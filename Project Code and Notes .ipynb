{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ab36b09",
   "metadata": {},
   "source": [
    "# Meeting One (ideally would have gone like this)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c76b05",
   "metadata": {},
   "source": [
    "## Our Goals and Aspirations With This Project\n",
    "\n",
    "A retail company “ABC Private Limited” wants to understand the customer purchase behaviour (specifically, purchase amount) against various products of different categories. They have shared purchase summaries of various customers for selected high-volume products from last month.\n",
    "The data set also contains customer demographics (age, gender, marital status, city type, stay in the current city), product details (productid and product category) and Total purchase amount from last month.\n",
    "\n",
    "Now, they want to build a model to predict the purchase amount of customers against various products which will help them to create a personalized offer for customers against different products.\n",
    "\n",
    "#### Tasks to perform\n",
    "\n",
    "- The purchase column is the Target Variable, perform Univariate Analysis and Bivariate Analysis w.r.t the Purchase.\n",
    "\n",
    "- Masked in the column description means already converted from categorical value to numerical column.\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b31b08df",
   "metadata": {},
   "source": [
    "### Roadmap\n",
    "\n",
    "Every ML project begins with the following pipeline in mind:\n",
    "![image.png](attachment:image.png)\n",
    "It is not a requisite for us to think about these steps actively as we try to build our project but following them in an orderly manner just saves us from a world of pain when we try to really work with our data and have it speak to us.You'll understand better when we start cleaning our data, visualizing it, observing trends, and weeding out the features that do not help us with our predictions.<br><br>\n",
    "Let's get into the building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c4de4",
   "metadata": {},
   "source": [
    "Here is the life blood of our code - libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3203ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Data frame: https://pandas.pydata.org/docs/getting_started/index.html#getting-started \n",
    "import numpy as np  # Arrays and matrices that make calculations easier: https://numpy.org/\n",
    "import matplotlib.pyplot as plt  # https://matplotlib.org/stable/users/getting_started/index.html\n",
    "from sklearn.impute import SimpleImputer  # Replace missing values using a descriptive statistic: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "from sklearn.preprocessing import LabelEncoder  # Encode target labels with value between 0 and n_classes-1.\n",
    "from sklearn.linear_model import LinearRegression  #https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "from sklearn.model_selection import KFold  # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # https://scikit-learn.org/stable/api/sklearn.metrics.html\n",
    "from sklearn import model_selection  # https://scikit-learn.org/stable/api/sklearn.model_selection.html\n",
    "from sklearn.linear_model import Ridge  # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "from sklearn.linear_model import Lasso  # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "from sklearn.neighbors import KNeighborsRegressor  # https://scikit-learn.sourceforge.net/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "from sklearn.tree import DecisionTreeRegressor  # https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "from sklearn.ensemble import RandomForestRegressor  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "import types  # https://docs.python.org/3/library/types.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b95769a",
   "metadata": {},
   "source": [
    "## Data Input: Gathering Raw Data\n",
    "\n",
    "\n",
    "<br>Most ML projects start with one big data set that you need to later split into subsections according to your training and testing needs, but us blessed folk have our data split into training and testing data by the datset gods, so lets go ahead and import that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e4c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(r'./Data/train.csv')\n",
    "dataset_test = pd.read_csv(r'./Data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d936cf6b",
   "metadata": {},
   "source": [
    "A little sneak peak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "59eec8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550068\n",
      "233599\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0               999.0               999.0      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2               999.0               999.0      1422  \n",
       "3                14.0               999.0      1057  \n",
       "4               999.0               999.0      7969  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset_train))  # Number of rows in training data.\n",
    "print(len(dataset_test))  # Number of rows in testing data.\n",
    "dataset_train.head()  # Top 5 rows of our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3009c",
   "metadata": {},
   "source": [
    "You see all those weird values in the \"Product_Category_2\" and \"Product_Category_3\" columns? The ones that look look like \"NaN\"?<br> Yeah, those are really pesky values that stand for \"Not a Number\" and can mess up our model when it tries to do its elegant, super smart calculations. These NaN values are simulations of inconsistencies in real-life data that we need to clean before we move any further in our journey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c97a5a7",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "We're gonna make a bunch of functions that clean out those NaN values, standarize our categorical data point and sets some rules that our datset will follow.<br>This might seem like tedious work before you get to the meat of the project but the it is going to be a lifesaver later. Trust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954bcb7b",
   "metadata": {},
   "source": [
    "Let's find the unique values in our data and create a dictionary to store them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fe2c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender ['F' 'M']\n",
      "Age ['0-17' '18-25' '26-35' '36-45' '46-50' '51-55' '55+']\n",
      "Occupation [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "City_Category ['A' 'B' 'C']\n",
      "Stay_In_Current_City_Years ['0' '1' '2' '3' '4+']\n",
      "Marital_Status [0 1]\n",
      "Product_Category_1 [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Product_Category_2 [ 2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18. nan]\n",
      "Product_Category_3 [ 3.  4.  5.  6.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18. nan]\n"
     ]
    }
   ],
   "source": [
    "columns = dataset_train.columns  # Extracting column names from our training df.\n",
    "dic_columnwise_acceped_value = {}   # Creating a dictionary.\n",
    "for i in columns[2:-1] :  # [2:-1] excludes the first two and the last columns from the loop.\n",
    "    temp1 = dataset_train[i].unique()  # Extract unique values from the current column in the training df.\n",
    "    temp2 = dataset_test[i].unique()  # Extract unique values form the current column in the testing df.\n",
    "    try :  # Handles potential TypeError exceptions that might occur if the column contains non-numeric values (coughNaNcough).\n",
    "        if np.isnan(temp1).any() and np.isnan(temp2).any() :  # If any of the unique values is temp1 and temp2 are NaN,\n",
    "            temp1 = temp1[~np.isnan(temp1)]  # get rid of them.\n",
    "    except TypeError :\n",
    "        pass\n",
    "    tem_dup =  np.hstack([temp1, temp2])  # Concatenates the cleaned unique values.\n",
    "    tem_dup = np.unique(tem_dup)  # Since we combined two different arrays we'll get the unique values from this concatenation.\n",
    "    dic_columnwise_acceped_value[i] = list(tem_dup)  # Using the column names as keys, store the entire list of unique values.\n",
    "    print(i,tem_dup)  # Printing the current column and all its unique values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b9aa3b",
   "metadata": {},
   "source": [
    "Now lets count the null/NaN values in our columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbde0c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2            173638\n",
      "Product_Category_3            383247\n",
      "Purchase                           0\n",
      "dtype: int64\n",
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2             72344\n",
      "Product_Category_3            162562\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.isna().sum())  # Calculates the sum of null/NaN in training data.\n",
    "print(dataset_test.isna().sum())  # Calculates the sum of null/NaN in testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a94244",
   "metadata": {},
   "source": [
    "#### Function 1: replace_NaN \n",
    "Replacing all those null/NaN values with 999 so that they can be encoded later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9974126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_NaN(data, columns, *args) :  # Parameters, df containing the data, column names, list of     \n",
    "    # Identify NaN values and assign them with a constant valu of 999.\n",
    "    mp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=999)\n",
    "    # Now lets fit our designed imputer to trasnformed_val.\n",
    "    # transform_val contains a set of numpy arrays of the chosen columns from our data.\n",
    "    transformed_val = mp.fit_transform(data.iloc[:,[columns.get_loc(i) for i in list(args)]].values)\n",
    "    df = data.copy()  # Creating a copy of the data.\n",
    "    df[list(args)] = transformed_val  # Assigns the transformed data to the copy to return.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40756d0d",
   "metadata": {},
   "source": [
    "Use this function on Product Category 2 and 3 and see the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "21380776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Product_Category_2', 'Product_Category_3')\n",
      "('Product_Category_2', 'Product_Category_3')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0               999.0               999.0      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2               999.0               999.0      1422  \n",
       "3                14.0               999.0      1057  \n",
       "4               999.0               999.0      7969  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making those modifications on training and testing data.\n",
    "dataset_train = replace_NaN(dataset_train, dataset_train.columns, 'Product_Category_2', 'Product_Category_3')\n",
    "dataset_test = replace_NaN(dataset_test, dataset_test.columns, 'Product_Category_2', 'Product_Category_3')\n",
    "\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7c822",
   "metadata": {},
   "source": [
    "# Meeting Two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b9bf0",
   "metadata": {},
   "source": [
    "#### Function 2: replace_column_with_Dummy_Columns\n",
    "A bunch of our columns have categorical data (City_Category, for example) that we want to convert to a form that is more computable in our functions. To do this, we will create dummy variables to store these values...<br><br>\n",
    "BUT, there is a problem that can arise through thise process. It is called the dummy variable trap.<br>\n",
    "The dummy variable trap occurs when you include all possible categories of categorical variables as dummies in a regression model.This leads to perfect multicollinearity, as one dummy variable can be perfectly predicted by the others. This causes problems during model estimation and prediction.<br>\n",
    "We're gonna deal with this by creating (n - 1) number of dummy variables for every categorical column containing n different categories containing either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7201d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_column_with_Dummy_Columns(data, columns, column_name, remove_column_val, remove_one_dummy=False, dtype=int) :\n",
    "    # data: df\n",
    "    # columns: List of categorical columns\n",
    "    # column_name: Name of current column\n",
    "    # remove_column_val: Column name with the highest number of unique values.\n",
    "    # remove_one_dummy: Whether to remove a dummy variable or not.\n",
    "    \n",
    "    # Creates dummy variables for the given 'column_name'.    \n",
    "    temp = pd.get_dummies(data[column_name], prefix=column_name, dtype=dtype)\n",
    "    col = list(temp.columns)\n",
    "    # removed_col will contain the dummy variable extracted from the original column.\n",
    "    removed_col = column_name+'_'+remove_column_val\n",
    "    removed_col_index = col.index(removed_col)  # Index of dummy variable to be removed.\n",
    "    # If remove_one_dummy=True, then we remove one dummy variable to avoid the dummy variable trap of perfect multicollinearity.\n",
    "    temp = temp[col[:removed_col_index] + col[removed_col_index+(1 if remove_one_dummy else 0):]] \n",
    "    previous = data[columns[:columns.index(column_name)]]  # Contains the columns before our current categorical column.\n",
    "    after = data[columns[columns.index(column_name)+1:]]   # Contains the columns after our current categorical column.\n",
    "    previous = previous.join(temp)  # Joins the columns before with the dummy variables that we created.\n",
    "    previous = previous.join(after)  # Joins the columns after with the result.\n",
    "    # Returning a df with our currrent categorical column split into dummy variables.\n",
    "    return previous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0b95a",
   "metadata": {},
   "source": [
    "#### Function 3: get_dummy_dataset\n",
    "This function complements Function 2 and passes it all its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431a761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_dataset(data, columns, cat_col_list) :\n",
    "    # data: df\n",
    "    # List of all columns in data\n",
    "    # cat_col_list: List of all categorical columsn in data.\n",
    "    \n",
    "    col = cat_col_list\n",
    "    # Creating a df using a lambda function that passes only the columns with non-categorical data.\n",
    "    df = data[list(filter(lambda x: x not in cat_col_list, columns))]\n",
    "    for i in cat_col_list :  # Looping over list of categorical column names\n",
    "        # Creating a dictionary. Keys = categorical column names. Values: Number of unique values in those columns.\n",
    "        dic = data[i].value_counts().to_dict()\n",
    "        max_key = max(dic, key=dic.get) # Grabbing the categorical column names with the highest number of unique values.\n",
    "        # Calling Function 2 here to replace the current categorical column with dummy variables.\n",
    "        data = replace_column_with_Dummy_Columns(data, col, i, str(max_key), True)\n",
    "        col = list(data.columns)  # Now updating the names of the columns we have after extracting dummy variables.\n",
    "    df= df.join(data)  # Joining non-categorical columns with categorical columns.\n",
    "    return df  # Returning data set that has been completely split into dummy variables where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a4017",
   "metadata": {},
   "source": [
    "#### Function 4: get_encoded_dataset\n",
    "Calls the get_dummy_dataset function\n",
    "#### Function 5: get_label_encoded_data\n",
    "Encode categorical features in a DataFrame into numerical values. This is a common preprocessing step in machine learning, as most algorithms expect numerical input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b45930a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_dataset(dataset, category_column) :\n",
    "    columns = list(dataset.columns)  # List of all columns.\n",
    "    df = get_dummy_dataset(dataset, columns, category_column)\n",
    "    return df\n",
    "def get_label_encoded_data(df, label_col) :\n",
    "    for i in label_col :  # Looping over column names that need their values label encoded.\n",
    "        le = LabelEncoder()  # LabelEncoder object.\n",
    "        # Calling fit_transform on the current column, replacing categorical values with numerical ones.\n",
    "        df[i] = le.fit_transform(df[i])  # I really recommend looking at the documentation for this.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e263f06",
   "metadata": {},
   "source": [
    "#### Function 6: get_train_test_data\n",
    "This function is designed to split a dataset into training and testing sets, handling both DataFrames and NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec3188c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(df, slice_index, data_label) :\n",
    "    # slize_index: Index of the column in the data frame we want to slice till.\n",
    "    # data_label: df of just one column from df.\n",
    "    if type(data_label) is not pd.DataFrame :  # If it's not a data frame.\n",
    "        assert False\n",
    "    if type(df) is pd.DataFrame :  # If it is a data frame.\n",
    "        sliced_train_data = df.iloc[:slice_index,:]  # Selects rows from the beginning to the slice_index.\n",
    "        sliced_test_data = df.iloc[slice_index:, :]  # Selects rows from the slice_index to the end.\n",
    "        # Concatenates the training data with the label column, adding the label as a new column.\n",
    "        sliced_train_data = pd.concat([sliced_train_data, data_label], axis = 1)\n",
    "    else :  # Similar steps for a numpy array.\n",
    "        data_label = data_label.iloc[:, :].values\n",
    "        sliced_train_data = df[:slice_index]\n",
    "        sliced_test_data = df[slice_index:]\n",
    "        sliced_train_data = np.concatenate((sliced_train_data, data_label), axis = 1)\n",
    "    return sliced_train_data, sliced_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c6da3",
   "metadata": {},
   "source": [
    "#### Function 7: get_encoded_data\n",
    "Okay, it's all starting to come together now.<br><br>\n",
    "This function is designed to prepare a dataset for machine learning, i.e., all the models we are going to implement on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670c9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_data(dataset_train, dataset_test, model_type='non_tree_based') :\n",
    "    column = list(dataset_train.columns)  # List of all columns in the training set.\n",
    "    df = dataset_train[column[:-1]] # df contains all the columns from the training set except the last one - our target variable.\n",
    "    df = pd.concat([df, dataset_test], ignore_index=True) # Merging the training and testing datasets together.\n",
    "    category_column = ['Gender', 'Occupation', 'City_Category',\n",
    "                       'Product_Category_1', 'Product_Category_2',\n",
    "                       'Product_Category_3']  # Our categorical columns.\n",
    "    label_col = ['Age', 'Stay_In_Current_City_Years']  # Our columns that need label encoding.\n",
    "    if model_type == 'non_tree_based' :  # Not a tree based model? Do the following data cleaning.\n",
    "        df = get_label_encoded_data(df, label_col)  # Label encode these categorical features.\n",
    "        df = get_encoded_dataset(df, category_column)  # Create dummy variables for these categorical features.\n",
    "    elif model_type == 'tree_based' :  # Special treatment for tree based models.\n",
    "        # We will label encode ALL categorical features for tree based.\n",
    "        df = get_label_encoded_data(df, label_col+category_column)\n",
    "    else :\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e977781c",
   "metadata": {},
   "source": [
    "# Meeting Three"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb235a",
   "metadata": {},
   "source": [
    "#### Function 8:\n",
    "Calling function 7 depending on model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75655ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_model_based(dataset_train, dataset_test, model_type='non_tree_based') :\n",
    "    data_label = dataset_train[['Purchase']]  # Extracting target variable.\n",
    "    slice_index = len(dataset_train) \n",
    "    if model_type == 'non_tree_based' :\n",
    "        df = get_encoded_data(dataset_train, dataset_test, model_type)  # Encode our data.\n",
    "        df = df.drop(['User_ID', 'Product_ID'], axis = 1)  # Removing columns irrelevant to predicting purchases.\n",
    "        data_train, data_test = get_train_test_data(df, slice_index, data_label)  # Creating testing and training sets.\n",
    "    elif  model_type == 'tree_based' :\n",
    "        df = get_encoded_data(dataset_train, dataset_test, model_type)\n",
    "        df = df.drop(['User_ID', 'Product_ID'], axis = 1)\n",
    "        df = df.applymap(str)  # Converting all values in the dataframe to strings.\n",
    "        data_train, data_test = get_train_test_data(df, slice_index, data_label)\n",
    "    else  :\n",
    "        return None, None\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a42392",
   "metadata": {},
   "source": [
    "For non tree based Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e36d9047",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = get_data_model_based(dataset_train, dataset_test, model_type='non_tree_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bacd0",
   "metadata": {},
   "source": [
    "For tree based Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cf8edcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Age Occupation City_Category Stay_In_Current_City_Years  \\\n",
       "0      0   0         10             0                          2   \n",
       "1      0   0         10             0                          2   \n",
       "2      0   0         10             0                          2   \n",
       "3      0   0         10             0                          2   \n",
       "4      1   6         16             2                          4   \n",
       "\n",
       "  Marital_Status Product_Category_1 Product_Category_2 Product_Category_3  \\\n",
       "0              0                  2                 17                 15   \n",
       "1              0                  0                  4                 10   \n",
       "2              0                 11                 17                 15   \n",
       "3              0                 11                 12                 15   \n",
       "4              0                  7                 17                 15   \n",
       "\n",
       "   Purchase  \n",
       "0      8370  \n",
       "1     15200  \n",
       "2      1422  \n",
       "3      1057  \n",
       "4      7969  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatb_train, datatb_test = get_data_model_based(dataset_train, dataset_test, model_type='tree_based')\n",
    "datatb_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638977a",
   "metadata": {},
   "source": [
    "#### Function 9:\n",
    "Create a function which return train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9158423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train_data(data) :\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "    X_train, X_test, y_train , y_test = model_selection.train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "    return (X_train, X_test, y_train , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc3845",
   "metadata": {},
   "source": [
    "Okay, phew. We are done here. We have completed creating all the functions we need to make sure our dataset looks and acts the way we want it to so that we can go ahead and make our models and get to the juicy part of our project.\n",
    "\n",
    "BUT before that (I know and I'm sorry)!!!<br>\n",
    "\n",
    "We are going to create a generic class for our models. This class will store a bunch of information for our models, like their names, cross validation scores, etc. This will make for easy access of our models as objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75298948",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelObject :\n",
    "    def __init__(self, name) :\n",
    "        self._name = name\n",
    "        self._cross_validation_score = None\n",
    "        self._model = None\n",
    "    @property\n",
    "    def name(self) :\n",
    "        return self._name\n",
    "    @property\n",
    "    def cross_validation_score(self) :\n",
    "        return self._cross_validation_score\n",
    "    @cross_validation_score.setter\n",
    "    def cross_validation_score(self, value) :\n",
    "        try :\n",
    "            self._cross_validation_score = value\n",
    "        except Exception as e:\n",
    "            raise Exception('value object is not in format',e)\n",
    "    @property\n",
    "    def model(self) :\n",
    "        return self._model\n",
    "    @model.setter\n",
    "    def model(self, value) :\n",
    "        self._model = value\n",
    "        self._cross_validation_score = None\n",
    "    def __str__(self) :\n",
    "        res = '\\n'\n",
    "        res += 'Model Name :- ' + self._name + '\\n'\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec2e70",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Models we are going to train:\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- K-Nearest Neighbors Regression\n",
    "- Decision Tree Regression\n",
    "- Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b37e85",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Linear regression models the relationships between at least one explanatory variable and an outcome variable. This flexible analysis allows you to separate the effects of complicated research questions, allowing you to isolate each variable’s role.\n",
    "\n",
    "Linear regression has two primary purposes—understanding the relationships between variables and prediction:\n",
    "- The coefficients represent the estimated magnitude and direction (positive/negative) of the relationship between each independent variable and the dependent variable.\n",
    "- The equation allows you to predict the mean value of the dependent variable given the values of the independent variables that you specify.\n",
    "\n",
    "Arguably the most important numbers in the output of the regression table are the regression coefficients. Yet, despite their importance, what the heck do they mean?\n",
    "\n",
    "In a linear regression equation that looks like: $y = b_0 + b_1x_1 + b_2x_2$\n",
    "- $b_0$ represents the intercept of the line of best fit. It is where the line meets the y-axis.\n",
    "- $b_1$ and $b_2$ represent the factor that y changes by when $x_1$ or $x_2$ change respectively.\n",
    "\n",
    "By adjusting these coefficients, we can fit the line to the data points and make predictions.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bc045e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_modellr(X_train, y_train) :\n",
    "    seed_k_fold = 7  # Random seed\n",
    "    no_of_split = 10  # Partitioning your data set into 10 bins of equal size\n",
    "    # = (number of data points in data set/10) number of data points per bin\n",
    "    scoring = 'neg_mean_squared_error'  # Scoring metric \n",
    "    lr = ModelObject('Linear Regression')  # Storing the model in our custom object.\n",
    "    kfold = model_selection.KFold(n_splits= no_of_split, shuffle = True, random_state=seed_k_fold)  # K-Fold cross validator.\n",
    "    # Linear regression model instance.\n",
    "    lr.model = LinearRegression(fit_intercept=True, copy_X=True, n_jobs=None)\n",
    "    cv_results = -model_selection.cross_val_score(lr.model, X_train, y_train,cv=kfold, scoring=scoring)\n",
    "    # Performs cross-validation, calculating the negative mean squared error for each fold.\n",
    "    # The negative sign is used because the cross_val_score function maximizes the score, but we want to minimize it.\n",
    "    cv_results.sort(axis=-1, kind='mergesort', order=None)  # Sorting cross validation scores in ascending order.\n",
    "    lr.cross_validation_score = cv_results  # Storing the sorted results in our object.\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6f87f",
   "metadata": {},
   "source": [
    "Another important concept in this piece of code is the mean squared error.<br>\n",
    "Mean Squared Error (MSE) is a way to measure how accurate your model's predictions are. It does so using the following formula: \n",
    "$$MSE = \\frac{1}{n} * \\Sigma(y_i - ŷ^i)^2$$\n",
    "\n",
    "Where:\n",
    "- n: Number of data points\n",
    "- $y_i$: Actual value of the ith data point\n",
    "- $ŷ_i$: Predicted value of the ith data point\n",
    "\n",
    "There is actually more important detail in why it is a squared error:\n",
    "- Punishes Larger Errors: Squaring larger errors amplifies their impact on the overall MSE, making the model more sensitive to larger prediction mistakes.\n",
    "- Eliminates Negative Values: Squaring ensures that all errors are positive, regardless of whether the prediction was over or under the actual value. No cancelling of errors of the opposite sign.\n",
    "\n",
    "From this above explanation, it then becomes clear that a lower MSE indicates a better-performing model. It means that, on average, your model's predictions are closer to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04485881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr mean - 8890392.295194753\n"
     ]
    }
   ],
   "source": [
    "data = get_test_train_data(data_train.values)  # Getting training and testing data.\n",
    "if data is not None :\n",
    "    X_train, X_test, y_train , y_test = data[0], data[1], data[2], data[3]\n",
    "    lr = get_optimal_modellr(X_train, y_train)  # Calling the model on our data.\n",
    "    print('cr mean -',lr.cross_validation_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879dead",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "Ridge Regression is a linear regression technique that adds a penalty term to the cost function. This penalty term is proportional to the square of the magnitude of the model's coefficients. This modification helps to prevent overfitting, especially when dealing with multicollinearity.\n",
    "\n",
    "When training this model we use a specialized optimization algorithm like gradient descent that basically minimizes the cost function by fine tuning the parameters of the following equation:<br>\n",
    "$$Cost(w) = MSE(w) + \\alpha * ||w||^2$$\n",
    "Where:\n",
    "- MSE: Mean squared error\n",
    "- $\\alpha$: Regularization parameter that is up to us to set. This controls the strength of the penalty.\n",
    "- $||w||^2$: Sum of squared coefficients.\n",
    "\n",
    "Linear regression doesn't take all these measures to prevent overfitting and regularization of its parameters, which makes ridge regression a great alternative to simply complex models by reducing the impact of less important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60281930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ridge_regression_model(lambda_val) :\n",
    "    # This function creates a Ridge model with the specified parameters.\n",
    "    return Ridge(alpha = lambda_val, fit_intercept=True, copy_X=True,\n",
    "                         max_iter=None, tol=0.001, solver='auto', random_state=0)\n",
    "def get_optimal_model_ridge(X_train, y_train, verbose=True, lambda_start=0.001, lambda_stop=1.2, no_split=10) :\n",
    "    # X_train: Training data features\n",
    "    # y_train: Training target data.\n",
    "    # verbose: If set to True prints the current lambda value and its corresponding MSE.\n",
    "    # lambda_start: Starting value for tuning the alpha parameter.\n",
    "    # lambda_end: Ending value for tuning the alpha parameter.\n",
    "    seed_k_fold = 7\n",
    "    no_of_split = no_split\n",
    "    # Creates a list of lambda values using np.logspace (logarithmic spacing) to explore different regularization strengths.\n",
    "    range_lambda  = np.logspace(lambda_start, lambda_stop, num=no_split)\n",
    "    kf = model_selection.KFold(n_splits= no_of_split, shuffle = True, random_state=seed_k_fold)\n",
    "    index = 0  # Variable to iterate over range_lambda\n",
    "    val_score_list = []  # List to store MSEs.\n",
    "    #Applying cross validation for getting appropriate value of lambda\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_tr, X_tst = X_train[train_index], X_train[test_index]  # Data for the current kf split.\n",
    "        y_tr, y_tst = y_train[train_index], y_train[test_index]  # Target value for the current kf split.\n",
    "        temp = get_ridge_regression_model(range_lambda[index])  # Creating a model with the current lambda value.\n",
    "        temp.fit(X_tr,y_tr)  # Fitting model to data.\n",
    "        predicted = temp.predict(X_tst)  # Model prediction on testing data.\n",
    "        validation_score = mean_squared_error(y_tst, predicted)  # MSE between prediction and truth.\n",
    "        val_score_list.append(validation_score)  # Appending to MSE list.\n",
    "        if verbose :  # If we want to print parameter details.\n",
    "            print('lambda - '+str(range_lambda[index]) + '--validation score '+str(validation_score))\n",
    "        index += 1  # Next lambda value.\n",
    "    min_val_score_index = val_score_list.index(min(val_score_list))  # Index of the minimum validation score in the list.\n",
    "    lambda_optimal = range_lambda[min_val_score_index]  # Setting the optimal lambda as the one with the smallest error.\n",
    "    ridge_reg = ModelObject('Ridge Regression')  # Creating out custom ridge model.\n",
    "    ridge_reg.model = get_ridge_regression_model(lambda_optimal)\n",
    "    ridge_reg.cross_validation_score = val_score_list[min_val_score_index]\n",
    "    return ridge_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38fb9cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda - 1.0023052380778996--validation score 8978116.035017146\n",
      "lambda - 1.362141492331366--validation score 8834793.865385538\n",
      "lambda - 1.8511620758251646--validation score 8908186.709295517\n",
      "lambda - 2.515745280696361--validation score 8819218.668562202\n",
      "lambda - 3.4189196073092853--validation score 8926592.541328598\n",
      "lambda - 4.646341333097262--validation score 8895176.915080752\n",
      "lambda - 6.314418080347418--validation score 8882163.354879225\n",
      "lambda - 8.581348815120236--validation score 8886852.77075453\n",
      "lambda - 11.66212730131956--validation score 8811348.86470554\n",
      "lambda - 15.848931924611133--validation score 8961546.13396617\n",
      "8886836.430429496\n"
     ]
    }
   ],
   "source": [
    "# fitting optimal model\n",
    "rr = get_optimal_model_ridge(X_train, y_train, verbose=True)\n",
    "rr.model.fit(X_train,y_train)\n",
    "predicted = rr.model.predict(X_test)\n",
    "print(mean_squared_error(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684cf8ea",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "Lasso Regression is another regularization technique, similar to Ridge Regression. However, it uses a different penalty term to shrink coefficients towards zero.\n",
    "$$Cost(w) = MSE(w) + \\alpha + ||w||$$\n",
    "In the above equation we see that $||w||$, the sum of the absolute values of the coefficients, is not squared. This tends to drive some of the coefficents to exactly zero when we use our optimization algorithm, which means that some features are completely weeded out from the prediction process. This is a really efficient way to only keep the features important to our prediction.\n",
    "\n",
    "Both Ridge and Lasso Regression are powerful techniques for regularizing linear regression models. While Ridge Regression shrinks coefficients, Lasso Regression can drive some coefficients to exactly zero, leading to feature selection. The choice between the two often depends on the specific problem and the desired level of feature selection and model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ca4cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lasso_regression_model(lambda_val) :\n",
    "    # precompute - Whether to use a precomputed Gram matrix to speed up calculations\n",
    "    # warm_start - When set to True, reuse the solution of the previous call to fit as initialization\n",
    "    return Lasso(alpha = lambda_val, fit_intercept=True, precompute=False,\n",
    "                            copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False,\n",
    "                            random_state=0, selection='cyclic')\n",
    "def get_optimal_model_lasso(X_train, y_train, verbose=True, lambda_start=0.001, lambda_stop=1.2, no_split=10) :\n",
    "    seed_k_fold = 7\n",
    "    no_of_split = no_split\n",
    "    range_lambda  = np.logspace(lambda_start, lambda_stop, num=no_split)\n",
    "    kf = model_selection.KFold(n_splits= no_of_split,  shuffle = True, random_state=seed_k_fold)\n",
    "    index = 0\n",
    "    val_score_list = []\n",
    "    #Applying cross validation for getting appropriate value of lambda\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_tr, X_tst = X_train[train_index], X_train[test_index]\n",
    "        y_tr, y_tst = y_train[train_index], y_train[test_index]\n",
    "        temp =  get_lasso_regression_model(range_lambda[index])\n",
    "        temp.fit(X_tr, y_tr)\n",
    "        predicted = temp.predict(X_tst)\n",
    "        validation_score = mean_squared_error(y_tst, predicted)\n",
    "        val_score_list.append(validation_score)\n",
    "        if verbose :\n",
    "            print('lambda - '+str(range_lambda[index]) + '--validation score '+str(validation_score))\n",
    "        index += 1\n",
    "    min_val_score_index = val_score_list.index(min(val_score_list))\n",
    "    lambda_optimal = range_lambda[min_val_score_index]\n",
    "    lasso_reg = ModelObject('Lasso Regression')\n",
    "    lasso_reg.model = get_lasso_regression_model(lambda_optimal)\n",
    "    lasso_reg.cross_validation_score = val_score_list[min_val_score_index]\n",
    "    return lasso_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ab43b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda - 1.0023052380778996--validation score 8986011.839973714\n",
      "lambda - 1.362141492331366--validation score 8854222.881837202\n",
      "lambda - 1.8511620758251646--validation score 8941909.587999776\n",
      "lambda - 2.515745280696361--validation score 8874736.604505302\n",
      "lambda - 3.4189196073092853--validation score 9018486.052216118\n",
      "lambda - 4.646341333097262--validation score 9059099.743177645\n",
      "lambda - 6.314418080347418--validation score 9089763.475188429\n",
      "lambda - 8.581348815120236--validation score 9211737.094443558\n",
      "lambda - 11.66212730131956--validation score 9282362.715421775\n",
      "lambda - 15.848931924611133--validation score 9621899.218051085\n",
      "8901754.690498047\n"
     ]
    }
   ],
   "source": [
    "# fitting optimal model\n",
    "lr = get_optimal_model_lasso(X_train, y_train, verbose=True)\n",
    "lr.model.fit(X_train,y_train)\n",
    "predicted = lr.model.predict(X_test)\n",
    "print(mean_squared_error(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c406d4",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Regression\n",
    "K-Nearest Neighbors (KNN) is a simple yet powerful algorithm used for both classification and regression tasks. In the context of regression, KNN predicts the value of a new data point by considering the values of its nearest neighbors. Here's how it works:\n",
    "- We start by picking a K value. This value determines the number of nearest neighbors we want to consider when trying to predict the value of a new data point.\n",
    "- For each data point in the training set, we calculate its distance from the new data point (computationally expensive) using something like the Euclidean distance formula: $$\\sqrt((x_2 - x_1)^2 + (y_2 - y_1)^2)$$\n",
    "- once we have done this, we find the K nearest neighbors and calculate the average value of the target variable for them. This becomes the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "722dd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knr_model(k=5) :\n",
    "    # Helper function to create the model.\n",
    "    algo = 'auto'  # Algorithm for efficient neighbor searches\n",
    "    return KNeighborsRegressor(n_neighbors=k, weights='uniform', algorithm=algo, leaf_size=30, p=2,\n",
    "                               metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "def get_optimal_model_knr(X_train, y_train,k_start=1, k_stop=5, verbose=True) :\n",
    "    range_k  = np.arange(k_start,k_stop+1,dtype=int)  # Trying a bunch of different k values as our hyper parameter.\n",
    "    X_tr, X_tst, y_tr, y_tst = model_selection.train_test_split(X_train, y_train, test_size = 0.1, random_state=0)\n",
    "    val_score_list = []\n",
    "    #Applying cross validation for getting appropriate value of k\n",
    "    for j in range_k:\n",
    "        temp = get_knr_model(j)\n",
    "        temp.fit(X_tr, y_tr)\n",
    "        predicted = temp.predict(X_tst)\n",
    "        validation_score = mean_squared_error(y_tst, predicted)\n",
    "        val_score_list.append(validation_score)\n",
    "        if verbose :\n",
    "            print('k - '+str(j) + '--validation score '+str(validation_score))\n",
    "    knr_reg = ModelObject('KNR')\n",
    "    k_optimal = val_score_list.index(min(val_score_list)) + 1\n",
    "    knr_reg.model = get_knr_model(k_optimal)\n",
    "    knr_reg.cross_validation_score = val_score_list[k_optimal-1]\n",
    "    return knr_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c38451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k - 1--validation score 16664483.7510794\n",
      "k - 2--validation score 12834655.087152889\n",
      "k - 3--validation score 11657062.174923116\n",
      "k - 4--validation score 11155011.495333023\n",
      "k - 5--validation score 10928020.567287188\n",
      "k - 6--validation score 10833433.072049519\n",
      "k - 7--validation score 10788816.737206059\n",
      "k - 8--validation score 10757636.924327435\n",
      "k - 9--validation score 10795851.88670737\n",
      "k - 10--validation score 10798200.665611735\n",
      "k - 11--validation score 10804706.997808337\n",
      "k - 12--validation score 10845958.086165648\n",
      "k - 13--validation score 10881461.761551073\n",
      "k - 14--validation score 10925390.285474405\n",
      "10861016.385875462\n"
     ]
    }
   ],
   "source": [
    "knr = get_optimal_model_knr(X_train, y_train, k_start=1, k_stop=14, verbose=True)\n",
    "knr.model.fit(X_train,y_train)\n",
    "predicted = knr.model.predict(X_test)\n",
    "print(mean_squared_error(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30777be0",
   "metadata": {},
   "source": [
    "Little side quest formatting our data for tree based models before we move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67ce9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_test_train_data(datatb_train.values)\n",
    "if data is not None :\n",
    "    X_train, X_test, y_train , y_test = data[0], data[1], data[2], data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee06d684",
   "metadata": {},
   "source": [
    "### Decision Tree Regression\n",
    "\n",
    "Decision Tree Regression is a supervised learning algorithm that partitions the feature space into smaller regions and predicts a value for each region.\n",
    "\n",
    "A decision tree has three parts:\n",
    "- Node: A decision point in the tree where it splits into two different values.\n",
    "- Branch: A path from node to child node.\n",
    "- Leaf node: A terminal node that makes a prediction.\n",
    "\n",
    "Here's how these parts are put together in this algorithm:\n",
    "- Root Node: Starts with the entire dataset.\n",
    "- Feature Selection: Selecting the feature and threshold value that allow us to split the data into subsets.\n",
    "- Recursive partitioning: Features that result in the largest reduction in error are selected recursively to split the data over.\n",
    "- Once the data is split this way, a new data point traverses the tree based on the feature values, reaching a leaf node. The predicted value is then the average target value of the training data points in that leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dec20117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree_model( max_depth_start = 10, max_depth_end = 14, min_samples_lf = 1, min_samples_splt = 2, verbose = True) :\n",
    "    # max_depth: Controls the depth of the tree. A deeper tree can capture more complex patterns but is prone to overfitting.\n",
    "    # min_samples_lf: Sets the minimum number of samples required to be at a leaf node. A higher value can prevent overfitting.\n",
    "    # min_samples_splt: Sets the minimum number of samples required to split a node. Higher value can prevent overfitting.\n",
    "    criteria = 'squared_error'  # Specifies the function to measure the quality of a split.\n",
    "    split = 'best'  # Selects the best split based on the impurity measure.\n",
    "    range_depth  = np.arange( max_depth_start, max_depth_end+1,dtype=int)\n",
    "    val_score_list = []\n",
    "    for j in range_depth:\n",
    "        dt = DecisionTreeRegressor(criterion=criteria, splitter=split, max_depth=j,\n",
    "                                 min_samples_split=min_samples_splt, min_samples_leaf=min_samples_lf,\n",
    "                                 min_weight_fraction_leaf=0.0,max_features=None, random_state=0,\n",
    "                                 max_leaf_nodes=None,min_impurity_decrease=0.0)\n",
    "        dt.fit(X_train, y_train)\n",
    "        predicted = dt.predict(X_test)\n",
    "        validation_score = mean_squared_error(y_test, predicted)\n",
    "        val_score_list.append(validation_score)\n",
    "        if verbose :\n",
    "            print('max depth {0} , minimum sample leaf - {1} minimum sample split {2}'.format(str(j), \n",
    "                                                                                          str(min_samples_lf),\n",
    "                                                                                         str(min_samples_splt)))\n",
    "    dt_reg = ModelObject('Decision Tree')\n",
    "    dt_optimal = val_score_list.index(min(val_score_list)) + 10\n",
    "    dt_reg.model = DecisionTreeRegressor(criterion=criteria, splitter=split, max_depth=dt_optimal,\n",
    "                                 min_samples_split=min_samples_splt, min_samples_leaf=min_samples_lf,\n",
    "                                 min_weight_fraction_leaf=0.0,max_features=None, random_state=0,\n",
    "                                 max_leaf_nodes=None,min_impurity_decrease=0.0)\n",
    "    dt_reg.cross_validation_score = val_score_list[dt_optimal-10]\n",
    "    return dt_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ec4ff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth 10 , minimum sample leaf - 10 minimum sample split 10\n",
      "max depth 11 , minimum sample leaf - 10 minimum sample split 10\n",
      "max depth 12 , minimum sample leaf - 10 minimum sample split 10\n",
      "max depth 13 , minimum sample leaf - 10 minimum sample split 10\n",
      "max depth 14 , minimum sample leaf - 10 minimum sample split 10\n",
      "8635754.983018016\n"
     ]
    }
   ],
   "source": [
    "dtr = get_decision_tree_model(10, 14, 10, 10)\n",
    "print(dtr.cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6026824",
   "metadata": {},
   "source": [
    "### Random Forest Regressor\n",
    "\n",
    "Random Forest Regression is a versatile machine learning algorithm that combines multiple decision trees to make more accurate predictions. It's a powerful technique that often outperforms single decision trees, especially when dealing with complex datasets. Here's how it works:\n",
    "- You start by creating multiple decision trees, each trained on a random subset of the data and each has a random subset of features selected at each node.\n",
    "- Each decision tree makes a prediction n a new data point.\n",
    "- Final prediction is the average of all predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9a363ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest_regressor_model(no_of_trees = 10, max_depth_start = 10, max_depth_end = 14, min_samples_lf = 10,\n",
    "                                              min_samples_splt = 10, verbose = True) :\n",
    "    criteria = 'squared_error'\n",
    "    range_depth  = np.arange( max_depth_start, max_depth_end+1,dtype=int)\n",
    "    val_score_list = []\n",
    "    for j in range_depth:\n",
    "        rf = RandomForestRegressor(n_estimators=no_of_trees, criterion=criteria, max_depth=j, min_samples_split=min_samples_splt,\n",
    "                                 min_samples_leaf=min_samples_lf, min_weight_fraction_leaf=0.0, max_features=None,\n",
    "                                 max_leaf_nodes=None, min_impurity_decrease=0.0, oob_score=False, n_jobs=None, random_state=0, verbose=0,\n",
    "                                 warm_start=False)\n",
    "        rf.fit(X_train, y_train)\n",
    "        predicted = rf.predict(X_test)\n",
    "        validation_score = mean_squared_error(y_test, predicted)\n",
    "        val_score_list.append(validation_score)\n",
    "        if verbose :\n",
    "            print('No of trees {0} max depth {1} , minimum sample leaf - {2} minimum sample split {3} - val_score {4}'.format(str(no_of_trees),\n",
    "                                                                                            str(j), \n",
    "                                                                                          str(min_samples_lf),\n",
    "                                                                                         str(min_samples_splt), str(validation_score)))\n",
    "    rf_reg = ModelObject('Random Forest Regressor')\n",
    "    rf_optimal = val_score_list.index(min(val_score_list)) + 10\n",
    "    rf_reg.model = RandomForestRegressor(n_estimators=no_of_trees, criterion=criteria, max_depth=rf_optimal, min_samples_split=min_samples_splt,\n",
    "                                 min_samples_leaf=min_samples_lf, min_weight_fraction_leaf=0.0, max_features=None,\n",
    "                                 max_leaf_nodes=None, min_impurity_decrease=0.0, oob_score=False, n_jobs=None, random_state=0, verbose=0,\n",
    "                                 warm_start=False)\n",
    "    rf_reg.cross_validation_score = val_score_list[rf_optimal-10]\n",
    "    return rf_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c4f05af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of trees 10 max depth 10 , minimum sample leaf - 10 minimum sample split 10 - val_score 8574274.627929388\n",
      "No of trees 10 max depth 11 , minimum sample leaf - 10 minimum sample split 10 - val_score 8538895.549244048\n",
      "No of trees 10 max depth 12 , minimum sample leaf - 10 minimum sample split 10 - val_score 8507212.565676408\n",
      "No of trees 10 max depth 13 , minimum sample leaf - 10 minimum sample split 10 - val_score 8482866.882549865\n",
      "No of trees 10 max depth 14 , minimum sample leaf - 10 minimum sample split 10 - val_score 8465086.444942314\n"
     ]
    }
   ],
   "source": [
    "rfr = get_random_forest_regressor_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4fa94",
   "metadata": {},
   "source": [
    "# Okay, we have a winner.\n",
    "\n",
    "If you examine all the MSE's our models have output, Random forest has given us the lowest value after some hyper parameter tuning. This bring us to the end of our project. All we have to do now is use this proven model on our data and get predictions for our target variable!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "533418a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashn\\OneDrive\\Documents\\AISC\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rfr.model.fit(X_train, y_train)  # Fitting the model to our testing data.\n",
    "final_predicted = rfr.model.predict(datatb_test)  # Predicting on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783174f",
   "metadata": {},
   "source": [
    "predicted now contains a 1D array of our predicted target variable. Let's concatenate this to our testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4ffd5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatb_test['Purchase'] = np.rint(final_predicted).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cf8a32cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>783662</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>7470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783663</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>6558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783664</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783665</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>20576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783666</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender Age Occupation City_Category Stay_In_Current_City_Years  \\\n",
       "783662      0   2         15             1                          4   \n",
       "783663      0   2         15             1                          4   \n",
       "783664      0   2         15             1                          4   \n",
       "783665      0   4          1             2                          4   \n",
       "783666      0   4          0             1                          4   \n",
       "\n",
       "       Marital_Status Product_Category_1 Product_Category_2  \\\n",
       "783662              1                  7                 17   \n",
       "783663              1                  4                  6   \n",
       "783664              1                  0                  3   \n",
       "783665              0                  9                 14   \n",
       "783666              1                  3                  3   \n",
       "\n",
       "       Product_Category_3  Purchase  \n",
       "783662                 15      7470  \n",
       "783663                 15      6558  \n",
       "783664                  8     13085  \n",
       "783665                 15     20576  \n",
       "783666                 15      2384  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatb_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a3438",
   "metadata": {},
   "source": [
    "*Isn't she lovely?<br>\n",
    "Isn't she wonderful?<br>\n",
    "Isn't she precious?<br>\n",
    "Less than one minute old<br>\n",
    "I never thought through love we'd be<br>\n",
    "Making one as lovely as she<br>\n",
    "But isn't she lovely made from love?*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34237e7e",
   "metadata": {},
   "source": [
    "Well congratulations! You are now data scientists! This is the end of the project. All your Red Bulls, sweat, and tears have paid off!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
